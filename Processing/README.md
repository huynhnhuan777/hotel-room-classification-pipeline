# ğŸ¨ Hotel Room Classification - Data Processing Pipeline

## ğŸ“‹ Tá»•ng Quan

Quy trÃ¬nh xá»­ lÃ½ dá»¯ liá»‡u cho bÃ i toÃ¡n **Multi-class Classification** nháº±m phÃ¢n loáº¡i phÃ²ng khÃ¡ch sáº¡n thÃ nh cÃ¡c lá»›p khÃ¡c nhau dá»±a trÃªn cÃ¡c Ä‘áº·c trÆ°ng cá»§a phÃ²ng.

---

## ğŸ¯ Äá»‹nh NghÄ©a BÃ i ToÃ¡n

### **Loáº¡i BÃ i ToÃ¡n**
- **Type**: Multi-class Classification (Supervised Learning)
- **Objective**: Dá»± Ä‘oÃ¡n lá»›p phÃ²ng (room_class) dá»±a trÃªn cÃ¡c Ä‘áº·c trÆ°ng cá»§a phÃ²ng
- **Method**: Supervised Learning

### **Biáº¿n Má»¥c TiÃªu (Target Variable)**
```
room_class: PhÃ¢n loáº¡i phÃ²ng thÃ nh 6 lá»›p (0, 1, 2, 3, 4, 5)
```

### **Biáº¿n Äáº§u VÃ o (Features)**
**Tá»•ng cá»™ng: 22 features**

#### 1. **GiÃ¡ Cáº£ (Price Features)** - 2 features
- `Final Price`: GiÃ¡ cuá»‘i cÃ¹ng cá»§a phÃ²ng (Ä‘Ã£ normalize)
- `price_per_m2`: GiÃ¡ trÃªn má»™t mÃ©t vuÃ´ng

#### 2. **KÃ­ch ThÆ°á»›c PhÃ²ng (Room Size)** - 3 features
- `Max People`: Sá»‘ ngÆ°á»i tá»‘i Ä‘a cÃ³ thá»ƒ á»Ÿ
- `Area_m2`: Diá»‡n tÃ­ch phÃ²ng (mÂ²)
- `m2_per_person`: Diá»‡n tÃ­ch trÃªn má»™t ngÆ°á»i

#### 3. **Loáº¡i GiÆ°á»ng (Bed Type)** - 6 features
- `is_king`: CÃ³ giÆ°á»ng king
- `is_queen`: CÃ³ giÆ°á»ng queen
- `is_double`: CÃ³ giÆ°á»ng Ä‘Ã´i
- `is_single`: CÃ³ giÆ°á»ng Ä‘Æ¡n
- `is_bunk`: CÃ³ giÆ°á»ng táº§ng
- `is_sofa`: CÃ³ giÆ°á»ng sofa

#### 4. **Tiá»‡n Ãch (Amenities)** - 10 features
- `has_luxury_keyword`: PhÃ²ng luxury
- `has_wifi`: WiFi miá»…n phÃ­
- `has_ac`: Äiá»u hÃ²a khÃ´ng khÃ­
- `has_breakfast`: Bao gá»“m bá»¯a sÃ¡ng
- `has_tv`: Tivi
- `has_pool`: Há»“ bÆ¡i
- `has_balcony`: Ban cÃ´ng/terace
- `has_parking`: Chá»— Ä‘á»— xe
- `has_kitchen`: NhÃ  báº¿p/kitchenette
- `has_fridge`: Tá»§ láº¡nh

#### 5. **Sá»‘ LÆ°á»£ng Tiá»‡n Ãch (Facilities Count)** - 1 feature
- `num_facilities`: Tá»•ng sá»‘ tiá»‡n Ã­ch trong phÃ²ng

---

## ğŸ”„ Quy TrÃ¬nh Xá»­ LÃ½ Dá»¯ Liá»‡u

### **Step 1: Load Train / Val CSV**
```python
# Load training and validation datasets
train_path = './Data/train.csv'
val_path = './Data/val.csv'

df_train = pd.read_csv(train_path)      # 8,497 samples
df_val = pd.read_csv(val_path)          # 1,822 samples
```

**Output:**
- Train set: 8,497 máº«u
- Val set: 1,822 máº«u

---

### **Step 2: Kiá»ƒm Tra Dá»¯ Liá»‡u (Data Inspection)**

Kiá»ƒm tra:
- âœ… KÃ­ch thÆ°á»›c dá»¯ liá»‡u (shape)
- âœ… Kiá»ƒu dá»¯ liá»‡u (data types)
- âœ… GiÃ¡ trá»‹ thiáº¿u (missing values)
- âœ… Thá»‘ng kÃª cÆ¡ báº£n (statistics)
- âœ… PhÃ¢n bá»‘ biáº¿n má»¥c tiÃªu (target distribution)

**Káº¿t quáº£:**
- âœ“ KhÃ´ng cÃ³ giÃ¡ trá»‹ thiáº¿u
- âœ“ PhÃ¢n bá»‘ target cÃ¢n báº±ng giá»¯a cÃ¡c lá»›p

---

### **Step 3: Chá»n Features + Target (Feature Selection)**

```python
# Define target and features
target = 'room_class'
X_train = df_train.drop(columns=[target])   # Features
y_train = df_train[target]                  # Target

X_val = df_val.drop(columns=[target])
y_val = df_val[target]
```

**Categorization of Features:**
| Category | Count | Features |
|----------|-------|----------|
| Price | 2 | Final Price, price_per_m2 |
| Room Size | 3 | Max People, Area_m2, m2_per_person |
| Bed Types | 6 | is_king, is_queen, is_double, is_single, is_bunk, is_sofa |
| Amenities | 10 | has_wifi, has_ac, has_breakfast, has_tv, has_pool, has_balcony, has_parking, has_kitchen, has_fridge, has_luxury_keyword |
| Facilities | 1 | num_facilities |
| **Total** | **22** | **All features** |

**Feature-Target Correlation:**
```
Top 3 correlated features with room_class:
1. Final Price        (correlation: highest)
2. Area_m2           (correlation: strong positive)
3. Max People        (correlation: moderate positive)
```

---

### **Step 4: Xá»­ LÃ½ Missing Values**

```python
# Check and handle missing values
missing_count = X_train.isnull().sum().sum()

if missing_count > 0:
    # For numerical: fill with mean
    # For categorical: fill with mode
    print("Missing values handled!")
else:
    print("âœ“ No missing values!")
```

**Status:** âœ… KhÃ´ng cÃ³ giÃ¡ trá»‹ thiáº¿u cáº§n xá»­ lÃ½

---

### **Step 5: Encode Categorical Features**

```python
from sklearn.preprocessing import LabelEncoder

if len(categorical_features) > 0:
    for col in categorical_features:
        le = LabelEncoder()
        X_train[col] = le.fit_transform(X_train[col].astype(str))
        X_val[col] = le.transform(X_val[col].astype(str))
else:
    print("âœ“ No categorical features to encode!")
```

**Status:** âœ… Táº¥t cáº£ features Ä‘Ã£ lÃ  numerical (khÃ´ng cáº§n encode)

---

### **Step 6: Scale Numerical Features**

```python
from sklearn.preprocessing import StandardScaler

# Apply StandardScaler: (x - mean) / std
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train[numerical_features])
X_val_scaled = scaler.transform(X_val[numerical_features])
```

**Scaling Method:** `StandardScaler`
- âœ“ Zero mean (Î¼ = 0)
- âœ“ Unit variance (Ïƒ = 1)
- âœ“ Giáº£m áº£nh hÆ°á»Ÿng cá»§a outliers
- âœ“ Cáº£i thiá»‡n hiá»‡u nÄƒng cÃ¡c mÃ´ hÃ¬nh ML

**Features Scaled:** Táº¥t cáº£ 22 numerical features

---

### **Step 7: LÆ°u Processed Dataset**

```python
# Save processed datasets
train_processed.to_csv('./Data/train_processed.csv', index=False)
val_processed.to_csv('./Data/val_processed.csv', index=False)

# Save processing objects
with open('./Data/scaler.pkl', 'wb') as f:
    pickle.dump(scaler, f)

with open('./Data/processing_metadata.json', 'w') as f:
    json.dump(metadata, f)
```

---

## ğŸ“ Output Files

```
Processing/Data/
â”œâ”€â”€ train_processed.csv          # 8,497 Ã— 23 (22 features + 1 target)
â”œâ”€â”€ val_processed.csv            # 1,822 Ã— 23
â”œâ”€â”€ scaler.pkl                   # StandardScaler object for test set
â””â”€â”€ processing_metadata.json     # Processing metadata
```

### **Processing Metadata:**
```json
{
  "scaling": {
    "scaler_type": "StandardScaler",
    "numerical_features": [...all 22 features...],
    "mean": [...mean values...],
    "scale": [...scale values...]
  },
  "encoding": {
    "categorical_features": [],
    "encoders": {}
  },
  "data_info": {
    "train_samples": 8497,
    "val_samples": 1822,
    "total_features": 22,
    "target": "room_class",
    "target_classes": 6
  }
}
```

---

## ğŸš€ CÃ¡ch Sá»­ Dá»¥ng

### **1. Cháº¡y Notebook**
```bash
# Má»Ÿ Processed.ipynb trong Jupyter
jupyter notebook Processed.ipynb

# Hoáº·c sá»­ dá»¥ng VS Code
# Ctrl + Shift + D Ä‘á»ƒ cháº¡y táº¥t cáº£ cells
```

### **2. Load Processed Data**
```python
import pandas as pd
import pickle

# Load processed data
train_processed = pd.read_csv('./Data/train_processed.csv')
val_processed = pd.read_csv('./Data/val_processed.csv')

# Load scaler for future test set
with open('./Data/scaler.pkl', 'rb') as f:
    scaler = pickle.load(f)

# For future predictions
X_test_scaled = scaler.transform(X_test)
```

### **3. Chuáº©n Bá»‹ cho Model Training**
```python
from sklearn.model_selection import train_test_split

# Separate features and target
X_train = train_processed.drop('room_class', axis=1)
y_train = train_processed['room_class']

X_val = val_processed.drop('room_class', axis=1)
y_val = val_processed['room_class']

# Ready for model training!
```

---

## ğŸ“Š Thá»‘ng KÃª Dá»¯ Liá»‡u

### **Data Split**
| Dataset | Samples | Features + Target | Percentage |
|---------|---------|------------------|-----------|
| Train | 8,497 | 23 | 82.3% |
| Val | 1,822 | 23 | 17.7% |
| **Total** | **10,319** | **23** | **100%** |

### **Target Distribution**
```
room_class 0: ~17%
room_class 1: ~17%
room_class 2: ~17%
room_class 3: ~17%
room_class 4: ~17%
room_class 5: ~15%
```
*(PhÃ¢n bá»‘ cÃ¢n báº±ng - Good for classification)*

### **Feature Statistics (After Scaling)**
- Mean (Î¼): 0 for all features
- Std Dev (Ïƒ): 1 for all features
- Range: Typically [-3, 3] (Gaussian distribution)

---

## âš™ï¸ Äiá»u Kiá»‡n TiÃªn Quyáº¿t

### **ThÆ° Viá»‡n Cáº§n Thiáº¿t**
```python
pandas >= 1.3.0
numpy >= 1.21.0
scikit-learn >= 0.24.0
matplotlib >= 3.4.0
seaborn >= 0.11.0
```

### **CÃ i Äáº·t**
```bash
pip install -r requirements.txt
```

---

## ğŸ“ Ghi ChÃº Quan Trá»ng

### **Scaling Considerations**
- âœ… StandardScaler Ä‘Æ°á»£c Ã¡p dá»¥ng cho Táº¤T Cáº¢ numerical features
- âœ… Fitted trÃªn training data
- âœ… Applied trÃªn validation data sá»­ dá»¥ng training parameters
- âš ï¸ **Important**: Khi predict trÃªn test set, pháº£i dÃ¹ng cÃ¹ng scaler nÃ y

### **Train-Val Split**
- âœ… Dá»¯ liá»‡u Ä‘Æ°á»£c split trÆ°á»›c khi xá»­ lÃ½
- âœ… Scaler Ä‘Æ°á»£c fit trÃªn train set
- âœ… Validation set Ä‘Æ°á»£c transform sá»­ dá»¥ng train parameters
- âœ… TrÃ¡nh data leakage

### **Missing Values**
- âœ… Dataset gá»‘c khÃ´ng cÃ³ missing values
- âœ… Logic xá»­ lÃ½ sáºµn cÃ³ trong code (mean cho numerical, mode cho categorical)

### **Categorical Features**
- âœ… Táº¥t cáº£ features Ä‘Ã£ lÃ  numerical
- âœ… KhÃ´ng cáº§n LabelEncoder hoáº·c OneHotEncoder
- âœ… CÃ¡c binary features (is_king, has_wifi...) lÃ  0/1

---

## ğŸ”— LiÃªn Káº¿t TÃ i Liá»‡u

- **Processed Notebook**: [Processed.ipynb](./Processed.ipynb)
- **Raw Data**: [train.csv](./Data/train.csv), [val.csv](./Data/val.csv)
- **Processed Data**: [train_processed.csv](./Data/train_processed.csv), [val_processed.csv](./Data/val_processed.csv)

---

## âœ… Checklist - Sáºµn SÃ ng cho Model Training

- [x] Load vÃ  kiá»ƒm tra dá»¯ liá»‡u
- [x] Chá»n features vÃ  target
- [x] Xá»­ lÃ½ missing values
- [x] Encode categorical features
- [x] Scale numerical features
- [x] LÆ°u processed datasets
- [ ] **Next Step**: Train classification models (Random Forest, Logistic Regression, SVM, etc.)

---

## ğŸ“š CÃ¡c BÆ°á»›c Tiáº¿p Theo

1. **Model Training** (`Random_Forest.ipynb`)
   - Train Random Forest Classifier
   - Hyperparameter tuning
   - Cross-validation

2. **Model Evaluation**
   - Accuracy, Precision, Recall, F1-score
   - Confusion Matrix
   - ROC-AUC curves

3. **Visualization** (`visualize_data_hotel.ipynb`)
   - Feature importance
   - Model performance visualization

---

## ğŸ‘¤ ThÃ´ng Tin TÃ¡c Giáº£

**Project**: Hotel Room Classification Pipeline
**Purpose**: Multi-class classification for hotel room categorization
**Date**: 2026

---

*Last Updated: January 23, 2026* âœ¨
