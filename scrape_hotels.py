import re
import time
import pandas as pd
from bs4 import BeautifulSoup

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC


# ================== Cáº¤U HÃŒNH ==================
INPUT_LINKS_TXT = "mytour_links.txt"   # má»—i dÃ²ng 1 link khÃ¡ch sáº¡n
OUT_CSV = "mytour_hotels.csv"

WAIT_AFTER_OPEN = 5      # vÃ o trang chá» 5s rá»“i má»›i láº¥y dá»¯ liá»‡u
WAIT_BEFORE_NEXT = 5     # láº¥y xong chá» 5s rá»“i má»›i sang trang khÃ¡c
# ==============================================


PRICE_RE = re.compile(r"(\d{1,3}(?:[.,]\d{3})+)\s*â‚«")
PERCENT_RE = re.compile(r"-\s*\d+\s*%")
RATING_RE = re.compile(r"^\d{1,2}(?:\.\d{1,2})?$")  # 9.4, 8.0, 10


def clean(text: str) -> str:
    if not text:
        return ""
    return re.sub(r"\s+", " ", text).strip()


def all_matches(pattern: re.Pattern, text: str):
    if not text:
        return []
    return [m.group(0) for m in pattern.finditer(text)]


def extract_hotel_name(soup: BeautifulSoup) -> str:
    h1 = soup.select_one("h1.MuiBox-root") or soup.select_one("h1")
    return clean(h1.get_text(" ", strip=True)) if h1 else ""


def extract_rating_score(soup: BeautifulSoup) -> str:
    best = ""
    for sp in soup.find_all("span"):
        t = clean(sp.get_text(" ", strip=True))
        if not t or not RATING_RE.match(t):
            continue
        try:
            val = float(t.replace(",", "."))
        except Exception:
            continue
        if not (0 <= val <= 10):
            continue

        has_svg = sp.find("svg") is not None or (sp.parent and sp.parent.find("svg") is not None)
        if has_svg:
            return t
        if not best:
            best = t
    return best


def extract_review_count(soup: BeautifulSoup) -> str:
    text = clean(soup.get_text(" ", strip=True)).lower()
    m = re.search(r"(\d[\d.,]*)\s*Ä‘Ã¡nh\s*giÃ¡", text)
    if m:
        return m.group(1).replace(".", "").replace(",", "")
    m = re.search(r"(\d[\d.,]*)\s*reviews?", text)
    if m:
        return m.group(1).replace(".", "").replace(",", "")
    return ""


def extract_address(soup: BeautifulSoup) -> str:
    btn = soup.find(
        lambda tag: tag.name in ("button", "span", "div")
        and clean(tag.get_text()).lower() == "xem báº£n Ä‘á»“"
    )
    if btn:
        container = btn.find_parent("div")
        if container:
            candidates = []
            for sp in container.find_all("span"):
                t = clean(sp.get_text(" ", strip=True))
                if len(t) < 8:
                    continue
                score = 0
                if "," in t:
                    score += 2
                if "viá»‡t nam" in t.lower():
                    score += 2
                if "há»“ chÃ­ minh" in t.lower() or "ho chi minh" in t.lower():
                    score += 2
                score += min(len(t) / 50, 2)
                candidates.append((score, t))
            if candidates:
                candidates.sort(key=lambda x: x[0], reverse=True)
                return candidates[0][1]

    full = clean(soup.get_text(" ", strip=True))
    m = re.search(r"([^\n]{10,200}viá»‡t nam[^\n]{0,50})", full, flags=re.IGNORECASE)
    if m:
        return clean(m.group(1))
    return ""


def extract_discount(soup: BeautifulSoup) -> str:
    for sp in soup.find_all(["span", "div"]):
        t = clean(sp.get_text(" ", strip=True))
        m = PERCENT_RE.search(t)
        if m:
            return m.group(0)
    return ""


def extract_amenities(soup: BeautifulSoup) -> str:
    """
    Tiá»‡n nghi: theo layout báº¡n Ä‘Æ°a (div.jss369 -> div.jss373 lÃ  tÃªn tiá»‡n nghi)
    Ná»‘i báº±ng " | "
    """
    amenities = []
    for block in soup.select("div.jss369"):
        name_div = block.select_one("div.jss373")
        if name_div:
            text = clean(name_div.get_text(" ", strip=True))
            if text:
                amenities.append(text)

    # loáº¡i trÃ¹ng nhÆ°ng giá»¯ thá»© tá»±
    return " | ".join(dict.fromkeys(amenities))


def extract_prices(soup: BeautifulSoup):
    """
    Tráº£ vá»: (giÃ¡_niÃªm_yáº¿t, discount, giÃ¡_hiá»‡n_táº¡i)
    GiÃ¡ hiá»‡n táº¡i = giÃ¡ niÃªm yáº¿t - giÃ¡ niÃªm yáº¿t * discount(%)
    """

    list_price_text = ""
    discount_text = ""
    current_price_text = ""

    # --- 1. TÃ¬m discount ---
    for sp in soup.find_all(["span", "div"]):
        t = clean(sp.get_text(" ", strip=True))
        m = PERCENT_RE.search(t)
        if m:
            discount_text = m.group(0)  # vÃ­ dá»¥ "-18%"
            break

    # --- 2. TÃ¬m giÃ¡ niÃªm yáº¿t ---
    prices = all_matches(PRICE_RE, clean(soup.get_text(" ", strip=True)))
    if prices:
        list_price_text = prices[0]   # láº¥y giÃ¡ Ä‘áº§u tiÃªn lÃ m giÃ¡ niÃªm yáº¿t

    # --- 3. TÃ­nh giÃ¡ hiá»‡n táº¡i ---
    if list_price_text:
        # chuyá»ƒn "2.894.667 â‚«" -> 2894667
        list_price_num = int(
            list_price_text.replace("â‚«", "")
            .replace(".", "")
            .replace(",", "")
            .strip()
        )

        if discount_text:
            discount_value = int(discount_text.replace("-", "").replace("%", ""))
            current_price_num = int(list_price_num * (100 - discount_value) / 100)
        else:
            current_price_num = list_price_num

        # format láº¡i tiá»n VNÄ
        current_price_text = f"{current_price_num:,}".replace(",", ".") + " â‚«"

    return list_price_text, discount_text, current_price_text

def load_links_from_txt(path: str):
    with open(path, "r", encoding="utf-8") as f:
        return [line.strip() for line in f if line.strip()]


def main():
    urls = load_links_from_txt(INPUT_LINKS_TXT)

    options = webdriver.ChromeOptions()
    options.add_argument("--start-maximized")
    # options.add_argument("--headless=new")

    driver = webdriver.Chrome(options=options)
    wait = WebDriverWait(driver, 25)

    rows = []

    try:
        for i, url in enumerate(urls, start=1):
            try:
                driver.get(url)

                # chá» h1 xuáº¥t hiá»‡n Ä‘á»ƒ cháº¯c cháº¯n trang load DOM chÃ­nh
                wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "h1")))

                # âœ… (1) vÃ o trang chá» 5s rá»“i má»›i láº¥y dá»¯ liá»‡u
                time.sleep(WAIT_AFTER_OPEN)

                # scroll nháº¹ Ä‘á»ƒ load cÃ¡c block Ä‘á»™ng (náº¿u cÃ³)
                for _ in range(2):
                    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                    time.sleep(1)

                soup = BeautifulSoup(driver.page_source, "lxml")

                hotel_name = extract_hotel_name(soup)
                rating_score = extract_rating_score(soup)
                review_count = extract_review_count(soup)
                address = extract_address(soup)
                list_price, discount, current_price = extract_prices(soup)
                amenities = extract_amenities(soup)

                rows.append({
                    "link": url,
                    "ten": hotel_name,
                    "gia_niem_yet": list_price,
                    "discount": discount,
                    "gia_hien_tai": current_price,
                    "dia_chi": address,
                    "so_luong_danh_gia": review_count,
                    "diem_danh_gia": rating_score,
                    "tien_nghi": amenities,
                })

                print(
                    f"[{i}/{len(urls)}] OK | {hotel_name} | "
                    f"list={list_price} | disc={discount} | now={current_price} | "
                    f"rating={rating_score} | reviews={review_count}"
                )

                # âœ… (2) láº¥y xong chá» 5s rá»“i má»›i sang trang khÃ¡c
                time.sleep(WAIT_BEFORE_NEXT)

            except Exception as e:
                print(f"[{i}/{len(urls)}] FAIL | {url} | {e}")
                time.sleep(WAIT_BEFORE_NEXT)

    finally:
        if rows:
            pd.DataFrame(rows).to_csv(
                OUT_CSV,
                index=False,
                sep=";",
                encoding="utf-8-sig"
            )
        driver.quit()

    print("ðŸŽ‰ DONE ->", OUT_CSV)


if __name__ == "__main__":
    main()
